{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOifx6JFEf1he+i6bHSrJ6t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DionesGouvea/Tera/blob/main/keras_F1_metric.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4383LH7X-Os"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow_addons.metrics import F1Score\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from keras.optimizers import Adam,Adamax,Nadam\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "# define o callback para salvar o modelo com a melhor métrica F1\n",
        "class F1ScoreModelCheckpoint(Callback):\n",
        "    def __init__(self, filepath, monitor='val_f1_score', mode='max', verbose=0, save_best_only=True, save_weights_only=False):\n",
        "        super(F1ScoreModelCheckpoint, self).__init__()\n",
        "        self.filepath = filepath\n",
        "        self.monitor = monitor\n",
        "        self.mode = mode\n",
        "        self.verbose = verbose\n",
        "        self.save_best_only = save_best_only\n",
        "        self.save_weights_only = save_weights_only\n",
        "        self.best_score = -np.inf\n",
        " \n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        score = logs[self.monitor]\n",
        "        if self.mode == 'max':\n",
        "            if score > self.best_score:\n",
        "                if self.verbose > 0:\n",
        "                    print(f\"\\nEpoch {epoch+1}: {self.monitor} improved from {self.best_score:.4f} to {score:.4f}\")\n",
        "                self.best_score = score\n",
        "                if self.save_weights_only:\n",
        "                    self.model.save_weights(self.filepath, overwrite=True)\n",
        "                else:\n",
        "                    self.model.save(self.filepath, overwrite=True)\n",
        "            elif self.verbose > 0:\n",
        "                print(f\"\\nEpoch {epoch+1}: {self.monitor} did not improve from {self.best_score:.4f}\")\n",
        "        else:\n",
        "            if score < self.best_score:\n",
        "                if self.verbose > 0:\n",
        "                    print(f\"\\nEpoch {epoch+1}: {self.monitor} improved from {self.best_score:.4f} to {score:.4f}\")\n",
        "                self.best_score = score\n",
        "                if self.save_weights_only:\n",
        "                    self.model.save_weights(self.filepath, overwrite=True)\n",
        "                else:\n",
        "                    self.model.save(self.filepath, overwrite=True)\n",
        "            elif self.verbose > 0:\n",
        "                print(f\"\\nEpoch {epoch+1}: {self.monitor} did not improve from {self.best_score:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# define as camadas da rede com regularização L2\n",
        "input_layer = Input(shape=(X.shape[1],))\n",
        "hidden_layer_1 = Dense(32, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01))(input_layer)\n",
        "hidden_layer_2 = Dense(80, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01))(hidden_layer_1)\n",
        "hidden_layer_3 = Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01))(hidden_layer_2)\n",
        "hidden_layer_4 = Dense(175, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01))(hidden_layer_3)\n",
        "#hidden_layer_5 = Dense(512, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01))(hidden_layer_4)\n",
        "#hidden_layer_6 = Dense(1024, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01))(hidden_layer_4)\n",
        "# concatena as camadas\n",
        "concat_layer = concatenate([hidden_layer_1, hidden_layer_2, hidden_layer_3,hidden_layer_4])\n",
        "\n",
        "# adiciona a camada de saída com regularização L2\n",
        "output_layer = Dense(1, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01))(concat_layer)\n",
        "\n",
        "# cria o modelo\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# define a métrica F1-score\n",
        "f1_score = F1Score(num_classes=1, threshold=0.5)\n",
        "\n",
        "# cria o otimizador\n",
        "optimizer = Nadam(learning_rate=0.00001)\n",
        "\n",
        "# compila o modelo com a métrica F1-score\n",
        "model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[f1_score])\n",
        "\n",
        "\n",
        "# treina o modelo e salva o modelo com a melhor métrica F1\n",
        "filepath = \"model_f1.h5\"\n",
        "checkpoint = F1ScoreModelCheckpoint(filepath, monitor='val_f1_score', mode='max')\n",
        "model.fit(X_train_final, y_train_final, epochs=2000, batch_size=127, validation_data=(X_val_final, y_val_final), callbacks=[checkpoint])\n",
        "\n",
        "# carrega o modelo com a melhor métrica F1\n",
        "model.load_weights(filepath)\n",
        "\n",
        "# faz a previsão no conjunto de teste\n",
        "y_pred = (model.predict(X_val_final) > 0.5)\n",
        "\n",
        "# avalia o desempenho do modelo\n",
        "_, f1 = model.evaluate(X_val_final, y_val_final, verbose=0)\n",
        "print(\"F1-score:\", f1)\n",
        "\n"
      ]
    }
  ]
}